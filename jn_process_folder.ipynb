{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "from preprocess.normalize import preprocess_signature\n",
    "import tf_signet\n",
    "from tf_cnn_model import TF_CNNModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import scipy.io\n",
    "from find_largest_image import find_largest\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model C:\\Users\\Mert\\Documents\\GitHub\\sigver_bmg\\models\\signet.pkl\n",
      "Using canvas size: [1338, 2973]\n",
      "WARNING:tensorflow:From c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8002it [00:10, 776.48it/s] \n"
     ]
    }
   ],
   "source": [
    "signatures_path = \"C:\\\\Users\\\\Mert\\\\Documents\\\\GitHub\\\\sigver_bmg\\\\data\\\\GPDSSyntheticSignatures4k\"\n",
    "model_path = \"C:\\\\Users\\\\Mert\\\\Documents\\\\GitHub\\\\sigver_bmg\\\\models\\\\signet.pkl\"\n",
    "canvas_size = [1338, 2973] \n",
    "print('Using model %s' % model_path)\n",
    "print('Using canvas size: %s' % (canvas_size,))\n",
    "sig_df = pd.DataFrame()\n",
    "# Load the model\n",
    "model_weight_path = model_path\n",
    "model = TF_CNNModel(tf_signet, model_weight_path)\n",
    "image_list = list()\n",
    "person_list = list()\n",
    "sig_num_list = list()\n",
    "fakeness_list = list()\n",
    "for root, dirs, filenames in tqdm.tqdm(os.walk(signatures_path, topdown=False)):\n",
    "    if (not root[-1].isdigit()) and not (root == signatures_path) : continue\n",
    "    for file in filenames:\n",
    "        if (file.endswith(\".jpg\")):\n",
    "            image_list.append(os.path.join(root,file))\n",
    "            person_list.append(int(root.split('\\\\')[-1]))\n",
    "            sig_num_list.append(int(file.split('-')[2].split('.')[0]))\n",
    "            if (file.startswith('cf')) : fakeness_list.append(1)\n",
    "            elif (file.startswith('c')) : fakeness_list.append(0)\n",
    "            else:\n",
    "                print(\"invalid character found in image file, quitting!\")\n",
    "                quit() \n",
    "image_list = np.asarray(image_list)\n",
    "person_list = np.asarray(person_list, dtype='uint16')\n",
    "sig_num_list = np.asarray(sig_num_list, dtype='uint16')\n",
    "fakeness_list = np.asarray(fakeness_list, dtype='int8')\n",
    "image_list = np.expand_dims(image_list, axis=1)\n",
    "person_list = np.expand_dims(person_list, axis=1)\n",
    "sig_num_list = np.expand_dims(sig_num_list, axis=1)\n",
    "fakeness_list = np.expand_dims(fakeness_list, axis=1)\n",
    "image_ndarray = np.zeros((len(image_list), 150, 220),dtype='uint8')\n",
    "data_ndarray = np.hstack((image_list, person_list, sig_num_list, fakeness_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/216000 [00:00<?, ?it/s]c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|████████████████████████████████████████████████████████████████████████| 216000/216000 [5:50:01<00:00,  6.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter, full_file_name in enumerate(tqdm.tqdm(image_list[:,0])):\n",
    "    image_ndarray[counter,:,:] = np.expand_dims(\n",
    "            preprocess_signature(imread(full_file_name, flatten=True),canvas_size),axis=0)\n",
    "    # if counter > 3 : break\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "splitter_coeff = 100\n",
    "i_slices = np.split(image_ndarray,splitter_coeff)\n",
    "vf_slices = np.split(np.zeros((len(image_list),2048)),splitter_coeff)\n",
    "del image_ndarray, image_list, person_list, sig_num_list, fakeness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for c_var, nd_slice in enumerate(tqdm.tqdm(i_slices)):\n",
    "    feature_vector = model.get_feature_vector_multiple(sess, nd_slice)\n",
    "    vf_slices[c_var] = feature_vector\n",
    "sig_v_df = pd.DataFrame(np.vstack(vf_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del i_slices, vf_slices\n",
    "sig_d_df = pd.DataFrame(data_ndarray)\n",
    "sig_d_df.rename(columns={0: 'path', 1: 'person', 2:'sig_num', 3:'fakeness'}, inplace=True)\n",
    "sig_d_df.to_csv(os.path.join(signatures_path,\"data_features.csv\"), index=False) \n",
    "sig_v_df.to_csv(os.path.join(signatures_path,\"visual_features.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
